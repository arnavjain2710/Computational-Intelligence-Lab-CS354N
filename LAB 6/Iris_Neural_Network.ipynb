{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model Architecture and BackPropagation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 1e1\n",
    "\n",
    "# Activation Function\n",
    "def sigmoid(x, grad = True):\n",
    "    value = 1/(1 + np.exp(-1*x)) \n",
    "    if grad:\n",
    "        # For Backpropagation\n",
    "        grad = value*(1-value)\n",
    "        return value, grad \n",
    "    return value\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_shape, output_shape, activation = sigmoid):\n",
    "        self.weight = np.random.normal(size=(input_shape, output_shape)) # Random Initialization of Weights\n",
    "        self.activation = activation\n",
    "    \n",
    "    def __call__(self, inp, grad):\n",
    "        output = self.weight.T @ inp # Forward Pass\n",
    "        if grad:\n",
    "            output, grad = self.activation(output, grad) \n",
    "            return output, grad\n",
    "        output = self.activation(output, grad) # Activation\n",
    "        return output\n",
    "\n",
    "\n",
    "class IrisClassifier:\n",
    "    def __init__(self, input_shape, output_shape, num_hidden_layers, num_hidden_neurons):\n",
    "        assert num_hidden_layers > 0, \"There should be at least one hidden layer\" # As required by the assignment\n",
    "        \n",
    "        if type(num_hidden_neurons) != list:\n",
    "            num_hidden_neurons = [num_hidden_neurons] * num_hidden_layers\n",
    "            \n",
    "        assert num_hidden_layers == len(num_hidden_neurons), \"The Number of Hidden Neurons should be in Number of Hidden Layers\" # Required for forward pass\n",
    "    \n",
    "        # Making the Feed Forward Neural Network\n",
    "        self.layers = [Perceptron(input_shape, num_hidden_neurons[0])] # First Layer\n",
    "        for i in range(num_hidden_layers-1):\n",
    "            self.layers.append(Perceptron(num_hidden_neurons[i], num_hidden_neurons[i+1])) # Hidden Layers\n",
    "        self.layers.append(Perceptron(num_hidden_neurons[-1], output_shape)) # Output Layer\n",
    "        self.grad = True\n",
    "    \n",
    "    # Entire Forward Pass\n",
    "    def __call__(self, input):\n",
    "        self.inputs = [input]\n",
    "        self.gradients = []\n",
    "        output, grad = self.layers[0](input, self.grad) # First Layer Forward Pass\n",
    "        self.gradients.append(grad)\n",
    "        for layer in self.layers[1:]:\n",
    "            self.inputs.append(output)\n",
    "            output, grad = layer(output, self.grad) # Passing the output of the previous layer to the next layer\n",
    "            self.gradients.append(grad)\n",
    "        return output\n",
    "    \n",
    "    # Backpropagation\n",
    "    def update_weights(self, grad_loss):\n",
    "        grad = self.gradients[-1] * grad_loss\n",
    "        self.layers[-1].weight -= grad * np.expand_dims(self.inputs[-1], axis=-1)\n",
    "        for i in range(len(self.layers)-1)[::-1]:\n",
    "            grad = np.expand_dims(self.gradients[i], axis=-1) * self.layers[i+1].weight @ grad            \n",
    "            self.layers[i].weight -= self.lr * np.expand_dims(self.inputs[i], axis=-1) @ np.expand_dims(grad, axis=-1).T \n",
    "\n",
    "    def train(self, X_train, y_train, X_test, y_test, learning_rate, n_epochs, logging_epochs = 10, validation_epochs = 100):\n",
    "        validation_epochs = min(validation_epochs, n_epochs)\n",
    "        self.lr = learning_rate\n",
    "        for current_epoch in range(0, n_epochs + 1):\n",
    "            total_loss = 0\n",
    "            train_accuracy = 0\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                pred = self(x) # Forward Pass\n",
    "                loss, grad_loss = MSELoss(pred, y) # Loss Calculation\n",
    "                total_loss += loss\n",
    "                train_accuracy += (y == (pred>=0.5))\n",
    "                self.update_weights(grad_loss) # Backpropagation\n",
    "            if current_epoch % logging_epochs == 0:\n",
    "                print(\"\\nEpoch: \", current_epoch)\n",
    "                print(\"Loss: \", total_loss/len(X_train))\n",
    "                print(\"Train Accuracy: \", train_accuracy/len(X_train))\n",
    "            \n",
    "            # Validation\n",
    "            if current_epoch % validation_epochs == 0:\n",
    "                val_loss = 0\n",
    "                val_accuracy = 0\n",
    "                for x, y in zip(X_test, y_test):\n",
    "                    pred = self(x)\n",
    "                    loss, _ = MSELoss(pred, y)\n",
    "                    val_loss += loss/len(X_test)\n",
    "                    val_accuracy += (y == (pred>=0.5))\n",
    "                print(\"Validation Loss: \", total_loss/len(X_test))\n",
    "                print(\"Validation Accuracy: \", val_accuracy/len(X_test))\n",
    "                \n",
    "        print(\"\\nTraining Finished!\")\n",
    "        print(\"Epoch: \", current_epoch)\n",
    "        print(\"Loss: \", total_loss/len(X_train))\n",
    "        print(\"Train Accuracy: \", train_accuracy/len(X_train))\n",
    "        \n",
    "        # Final Validation\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            pred = self(x)\n",
    "            loss, _ = MSELoss(pred, y)\n",
    "            val_loss += loss/len(X_test)\n",
    "            val_accuracy += (y == (pred>=0.5))\n",
    "        print(\"Validation Loss: \", total_loss/len(X_test))\n",
    "        print(\"Validation Accuracy: \", val_accuracy/len(X_test))\n",
    "\n",
    "# Loss Function\n",
    "def MSELoss(prediction, truth):\n",
    "    loss = 0.5 * (prediction - truth) ** 2\n",
    "    grad = prediction - truth\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n",
      "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
      "       'species'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_excel(\"iris_train.xlsx\")\n",
    "print(train_data.columns)\n",
    "\n",
    "test_data = pd.read_excel(\"iris_test.xlsx\")\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.4          3.9           1.7          0.4  setosa\n",
      "1           4.6          3.4           1.4          0.3  setosa\n",
      "2           5.0          3.4           1.5          0.2  setosa\n",
      "3           4.4          2.9           1.4          0.2  setosa\n",
      "4           4.9          3.1           1.5          0.1  setosa\n",
      "    sepal_length  sepal_width  petal_length  petal_width     species\n",
      "75           5.7          3.0           4.2          1.2  versicolor\n",
      "76           5.7          2.9           4.2          1.3  versicolor\n",
      "77           6.2          2.9           4.3          1.3  versicolor\n",
      "78           5.1          2.5           3.0          1.1  versicolor\n",
      "79           5.7          2.8           4.1          1.3  versicolor\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "    sepal_length  sepal_width  petal_length  petal_width     species\n",
      "15           6.8          2.8           4.8          1.4  versicolor\n",
      "16           6.7          3.0           5.0          1.7  versicolor\n",
      "17           6.0          2.9           4.5          1.5  versicolor\n",
      "18           5.7          2.6           3.5          1.0  versicolor\n",
      "19           5.5          2.4           3.8          1.1  versicolor\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "print(train_data.tail())\n",
    "\n",
    "print(test_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor']\n",
      "['setosa' 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.species.unique())\n",
    "print(test_data.species.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    values = [\"setosa\", \"versicolor\"]\n",
    "    return values.index(x)\n",
    "\n",
    "train_data[\"species\"] = train_data[\"species\"].apply(convert)\n",
    "test_data[\"species\"] = test_data[\"species\"].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           5.4          3.9           1.7          0.4        0\n",
      "1           4.6          3.4           1.4          0.3        0\n",
      "2           5.0          3.4           1.5          0.2        0\n",
      "3           4.4          2.9           1.4          0.2        0\n",
      "4           4.9          3.1           1.5          0.1        0\n",
      "    sepal_length  sepal_width  petal_length  petal_width  species\n",
      "75           5.7          3.0           4.2          1.2        1\n",
      "76           5.7          2.9           4.2          1.3        1\n",
      "77           6.2          2.9           4.3          1.3        1\n",
      "78           5.1          2.5           3.0          1.1        1\n",
      "79           5.7          2.8           4.1          1.3        1\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "print(test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the Dataset\n",
    "train_data = train_data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal_length  sepal_width  petal_length  petal_width  species\n",
      "7            4.8          3.0           1.4          0.1        0\n",
      "66           6.7          3.1           4.7          1.5        1\n",
      "34           5.1          3.8           1.9          0.4        0\n",
      "5            5.4          3.7           1.5          0.2        0\n",
      "2            5.0          3.4           1.5          0.2        0\n",
      "    sepal_length  sepal_width  petal_length  petal_width  species\n",
      "22           5.2          3.5           1.5          0.2        0\n",
      "74           5.6          2.7           4.2          1.3        1\n",
      "21           5.0          3.4           1.6          0.4        0\n",
      "9            5.8          4.0           1.2          0.2        0\n",
      "12           5.1          3.5           1.4          0.3        0\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train_data = train_data.to_numpy()\n",
    "np_test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np_train_data[:,:-1], np_train_data[:,-1]\n",
    "X_test, y_test = np_test_data[:,:-1], np_test_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 5), (20, 5))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np_train_data.shape, np_test_data.shape)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  0\n",
      "Loss:  [0.06153589]\n",
      "Train Accuracy:  [0.875]\n",
      "Validation Loss:  [0.24614358]\n",
      "Validation Accuracy:  [1.]\n",
      "\n",
      "Epoch:  5\n",
      "Loss:  [0.00326697]\n",
      "Train Accuracy:  [1.]\n",
      "\n",
      "Epoch:  10\n",
      "Loss:  [0.00164252]\n",
      "Train Accuracy:  [1.]\n",
      "Validation Loss:  [0.00657008]\n",
      "Validation Accuracy:  [1.]\n",
      "\n",
      "Epoch:  15\n",
      "Loss:  [0.00109697]\n",
      "Train Accuracy:  [1.]\n",
      "\n",
      "Epoch:  20\n",
      "Loss:  [0.00082412]\n",
      "Train Accuracy:  [1.]\n",
      "Validation Loss:  [0.00329646]\n",
      "Validation Accuracy:  [1.]\n",
      "\n",
      "Epoch:  25\n",
      "Loss:  [0.00066044]\n",
      "Train Accuracy:  [1.]\n",
      "\n",
      "Epoch:  30\n",
      "Loss:  [0.00055132]\n",
      "Train Accuracy:  [1.]\n",
      "Validation Loss:  [0.00220529]\n",
      "Validation Accuracy:  [1.]\n",
      "\n",
      "Epoch:  35\n",
      "Loss:  [0.00047337]\n",
      "Train Accuracy:  [1.]\n",
      "\n",
      "Training Finished!\n",
      "Epoch:  35\n",
      "Loss:  [0.00047337]\n",
      "Train Accuracy:  [1.]\n",
      "Validation Loss:  [0.0018935]\n",
      "Validation Accuracy:  [1.]\n"
     ]
    }
   ],
   "source": [
    "# IrisClassifier : input_shape, output_shape, num_hidden_layers, num_hidden_neurons\n",
    "model = IrisClassifier(4, 1, num_hidden_layers = 1, num_hidden_neurons = [15])\n",
    "# train method() : X_train, y_train, X_test, y_test, learning_rate, n_epochs, logging_epochs = 10, validation_epochs = 100\n",
    "model.train(X_train, y_train, X_test, y_test, 0.0001 , 35 , 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
